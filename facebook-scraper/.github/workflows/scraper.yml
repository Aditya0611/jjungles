name: Facebook Scraper - Scheduled Run

on:
  schedule:
    # Run every 3 hours
    - cron: '0 */3 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hour timeout for all categories
    permissions:
      contents: write  # Required for committing results
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch all history to ensure all files are available
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        echo "Installing system dependencies for Ubuntu 24.04..."
        sudo apt-get update
        echo "Step 1: Installing libasound2t64 (replaces libasound2 virtual package)..."
        sudo apt-get install -y libasound2t64
        echo "Step 2: Installing all other dependencies..."
        sudo apt-get install -y \
          libnss3 \
          libnspr4 \
          libatk1.0-0 \
          libatk-bridge2.0-0 \
          libcups2 \
          libdrm2 \
          libdbus-1-3 \
          libxkbcommon0 \
          libxcomposite1 \
          libxdamage1 \
          libxfixes3 \
          libxrandr2 \
          libgbm1 \
          libpango-1.0-0 \
          libcairo2
        echo "All system dependencies installed successfully!"
          
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        echo "Installing Playwright browsers..."
        playwright install firefox chromium
        echo "Browsers installed successfully"
        # Skip install-deps since we install system dependencies manually above
        
    - name: Verify config file exists
      run: |
        echo "=== Repository Information ==="
        echo "Current branch: $(git branch --show-current)"
        echo "Current commit: $(git rev-parse HEAD)"
        echo "Working directory: $(pwd)"
        echo ""
        echo "=== Directory Structure ==="
        ls -la
        echo ""
        echo "=== Config Directory ==="
        if [ -d "config" ]; then
          echo "Config directory exists"
          ls -la config/
        else
          echo "❌ Config directory NOT FOUND"
          echo "Creating config directory..."
          mkdir -p config
        fi
        echo ""
        echo "=== Checking for categories.json ==="
        if [ -f "config/categories.json" ]; then
          echo "✓ config/categories.json found"
          echo "File size: $(wc -c < config/categories.json) bytes"
          echo "File permissions: $(ls -l config/categories.json)"
          echo "First few lines:"
          head -5 config/categories.json
        else
          echo "❌ config/categories.json NOT FOUND"
          echo ""
          echo "Checking git for file:"
          git ls-files | grep categories.json || echo "File not tracked in git"
          echo ""
          echo "All JSON files in repository:"
          find . -name "*.json" -type f | head -20
          echo ""
          echo "All files in config directory:"
          find config -type f 2>/dev/null || echo "Config directory is empty or doesn't exist"
          exit 1
        fi
        
    - name: Create .env file
      env:
        FACEBOOK_EMAIL: ${{ secrets.FACEBOOK_EMAIL }}
        FACEBOOK_PASSWORD: ${{ secrets.FACEBOOK_PASSWORD }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        PROXIES: ${{ secrets.PROXIES }}
      run: |
        cat > .env << EOF
        FACEBOOK_EMAIL=${FACEBOOK_EMAIL}
        FACEBOOK_PASSWORD=${FACEBOOK_PASSWORD}
        SUPABASE_URL=${SUPABASE_URL}
        SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
        PROXIES=${PROXIES:-}
        EOF
        
    - name: Verify credentials (debug)
      run: |
        echo "=== Credential Check ==="
        if [ -n "$FACEBOOK_EMAIL" ]; then
          echo "✓ FACEBOOK_EMAIL is set (length: ${#FACEBOOK_EMAIL} chars)"
          echo "  Email starts with: ${FACEBOOK_EMAIL:0:3}***"
        else
          echo "❌ FACEBOOK_EMAIL is NOT set"
        fi
        if [ -n "$FACEBOOK_PASSWORD" ]; then
          echo "✓ FACEBOOK_PASSWORD is set (length: ${#FACEBOOK_PASSWORD} chars)"
        else
          echo "❌ FACEBOOK_PASSWORD is NOT set"
        fi
        echo ""
        
    - name: Run Facebook Scraper
      working-directory: ${{ github.workspace }}
      env:
        FACEBOOK_EMAIL: ${{ secrets.FACEBOOK_EMAIL }}
        FACEBOOK_PASSWORD: ${{ secrets.FACEBOOK_PASSWORD }}
      run: |
        echo "Working directory: $(pwd)"
        echo "Verifying config file exists before running script..."
        ls -la config/categories.json || exit 1
        echo "Running scraper..."
        python automated_scraper.py
        
    - name: Upload scraped data
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: scraped-data
        path: |
          data/*.json
          logs/*.log
        retention-days: 30
        
    - name: Commit and push results (optional)
      if: success()
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        # Ensure data directory exists
        mkdir -p data
        # Add JSON files if they exist
        if ls data/*.json 1> /dev/null 2>&1; then
          git add data/*.json
          git commit -m "Auto-scrape: $(date +'%Y-%m-%d %H:%M:%S UTC')" || exit 0
          git push || exit 0
        else
          echo "No JSON files to commit"
        fi

